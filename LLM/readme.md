# Large Language Models in OCI Data Science

OCI Data Science can be used to fine-tune, deploy, and manage Large Langugage Models (LLMs) effectively, efficiently, and easily.
This page curates the links to some common use cases for LLMs.

[Fine tune Llama 2 with distributed multi-node, multi-GPU job](https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/distributed_training/llama2)

[Quantize Llama 2 70B to 4 bits and deploy on 2xA10s](https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/LLM/Quantization)

[Deploy Llama 2 on fully service managed deployment using TGI or vLLM](https://github.com/oracle-samples/oci-data-science-ai-samples/tree/master/model-deployment/containers/llama2)

[Deploy Mistral 7B](https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/model-deployment/containers/llm/mistral)

[Deploy GPT-2 using NVidia Triton Inference Server](https://github.com/oracle-samples/oci-data-science-ai-samples/blob/main/model-deployment/containers/Triton/gpt2_ensemble/Deploy_GPT2_Ensemble.md)

## AI Quick Actions - Fine-tune, deploy, and evaluate LLMs without writing code
AI Quick Actions make working with LLMs super simple and requires no coding. From the AI Quick Actions extension in a Notebook session, you can explore foundation models, kickoff a fine-tuning process, deploy as a web endpoint and test it with a simple chat interface, and run evaluation jobs.
Learn more in this blog post:
[Introducing AI Quick Actions in OCI Data Science](https://blogs.oracle.com/ai-and-datascience/post/ai-quick-actions-in-oci-data-science)
