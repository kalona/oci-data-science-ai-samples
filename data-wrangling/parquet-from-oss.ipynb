{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da99b91",
   "metadata": {},
   "source": [
    "## Reading/Writing Parquet Files From/to OCI Object Storage with Pandas\n",
    "\n",
    "The setup for this notebook is simple. I used the `generalml_p37_cpu_v1` conda environment. This environment has ADS,pyarrow, pandas, snappy, and fastparquet pre-installed. \n",
    "\n",
    "I also upgraded the version of ADS. In this notebook ADS version 2.5.8 was used. \n",
    "\n",
    "To read/write files to Object Storage, use `ocifs` : \n",
    "* github.com/oracle/ocifs\n",
    "* docs: https://docs.oracle.com/en-us/iaas/tools/ocifs-sdk/latest/unix-operations.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install oracle-ads --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd62ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.8\n"
     ]
    }
   ],
   "source": [
    "import ads \n",
    "from ads.common.auth import default_signer\n",
    "import pandas as pd \n",
    "import fsspec\n",
    "from ocifs import OCIFileSystem\n",
    "\n",
    "# Using resource principal auth method: \n",
    "print(ads.__version__)\n",
    "ads.set_auth(auth=\"resource_principal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1c87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object storage bucket + data \n",
    "# this bucket is publicly available \n",
    "bucket = \"hosted-ds-datasets\"\n",
    "namespace = \"bigdatadatasciencelarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "696de748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ServiceError:\n",
      "{\n",
      "    \"client_version\": \"Oracle-PythonSDK/2.110.2, Oracle-PythonCLI/3.31.1\",\n",
      "    \"code\": \"BucketNotFound\",\n",
      "    \"logging_tips\": \"Please run the OCI CLI command using --debug flag to find more debug information.\",\n",
      "    \"message\": \"Either the bucket named 'hosted-ds-datasets' does not exist in the namespace 'bigdatadatasciencelarge' or you are not authorized to access it\",\n",
      "    \"opc-request-id\": \"fra-1:ZewZrFZQO0ZbOY29ZDJyuio-6ceCTAt_fHfUvZe1ora68c4CnYchC6ST33sckLBx\",\n",
      "    \"operation_name\": \"list_objects\",\n",
      "    \"request_endpoint\": \"GET https://objectstorage.eu-frankfurt-1.oraclecloud.com/n/bigdatadatasciencelarge/b/hosted-ds-datasets/o\",\n",
      "    \"status\": 404,\n",
      "    \"target_service\": \"object_storage\",\n",
      "    \"timestamp\": \"2023-08-23T10:33:08.654656+00:00\",\n",
      "    \"troubleshooting_tips\": \"See [https://docs.oracle.com/iaas/Content/API/References/apierrors.htm] for more information about resolving this error. If you are unable to resolve this issue, run this CLI command with --debug option and contact Oracle support and provide them the full error message.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!oci os object list --bucket-name {bucket} --namespace {namespace}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68024c",
   "metadata": {},
   "source": [
    "# Single Large File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2d5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 440 MB, 14M rows. \n",
    "large_files = [\"nyc_tlc/2009/01/data.parquet\"] # NYC Taxi dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the `pyarrow` engine. You can also use `fastparquet`. \n",
    "for f in large_files: \n",
    "    df = pd.read_parquet(f\"oci://{bucket}@{namespace}/{f}\", \n",
    "                     storage_options=default_signer(),\n",
    "                     engine=\"pyarrow\")\n",
    "    print(f\"file {f}\")\n",
    "    print(df.head())\n",
    "    print(f\"size {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06706b05",
   "metadata": {},
   "source": [
    "# Multiple Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d202b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oci.auth.signers import get_resource_principals_signer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using resource principal for authn. \n",
    "fs = OCIFileSystem(signer=get_resource_principals_signer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e146024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a small sample of the overall NYC Taxi dataset. There are 4 files in total, each of size ~ 450MB. \n",
    "relevant_files = fs.ls(f\"{bucket}@{namespace}/nyc_tlc/2009/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22421b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# this operation takes about 50 secs: \n",
    "df = pd.concat((pd.read_parquet(f\"oci://{f}/data.parquet\", storage_options=default_signer(), engine=\"pyarrow\") for f in relevant_files), \n",
    "               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 56M rows \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52a973",
   "metadata": {},
   "source": [
    "## Write Parquet Files to Object Storage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4923c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Writing the dataframe as a parquet file to Object Storage. \n",
    "# Insert the name of your bucket and namespace you want to write parquet. \n",
    "# this operation takes about 2 mins\n",
    "your_bucket = \"\"\n",
    "your_namespace = \"\"\n",
    "\n",
    "df.to_parquet(f\"oci://{your_bucket}@{your_namespace}/taxi-data.parquet\", \n",
    "                     storage_options=default_signer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oracle-ads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
